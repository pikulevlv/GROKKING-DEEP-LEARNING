{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Главы 9 - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усовершенствование сети для MNIST новым функциями активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "import numpy as np, sys\n",
    "np.random.seed(1) # фиксируем псевдослучайный генератор случайных чисел\n",
    "\n",
    "x_train = mnist.train_images()[:1000,:,:]\n",
    "y_train = mnist.train_labels()[:1000,...]\n",
    "\n",
    "x_test = mnist.test_images()[:2000,:,:]\n",
    "y_test = mnist.test_labels()[:2000,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0 Test_Accuracy: 0.323 Train_Accuracy: 0.206\n",
      "Iter:10 Test_Accuracy: 0.6395 Train_Accuracy: 0.72\n",
      "Iter:20 Test_Accuracy: 0.6615 Train_Accuracy: 0.748\n",
      "Iter:30 Test_Accuracy: 0.69 Train_Accuracy: 0.782\n",
      "Iter:40 Test_Accuracy: 0.7155 Train_Accuracy: 0.802\n",
      "Iter:50 Test_Accuracy: 0.7385 Train_Accuracy: 0.835\n",
      "Iter:60 Test_Accuracy: 0.753 Train_Accuracy: 0.849\n",
      "Iter:70 Test_Accuracy: 0.768 Train_Accuracy: 0.869\n",
      "Iter:80 Test_Accuracy: 0.7795 Train_Accuracy: 0.879\n",
      "Iter:90 Test_Accuracy: 0.7865 Train_Accuracy: 0.881\n",
      "Iter:100 Test_Accuracy: 0.792 Train_Accuracy: 0.888\n",
      "Iter:110 Test_Accuracy: 0.7985 Train_Accuracy: 0.898\n",
      "Iter:120 Test_Accuracy: 0.8005 Train_Accuracy: 0.898\n",
      "Iter:130 Test_Accuracy: 0.8085 Train_Accuracy: 0.901\n",
      "Iter:140 Test_Accuracy: 0.808 Train_Accuracy: 0.905\n",
      "Iter:150 Test_Accuracy: 0.816 Train_Accuracy: 0.92\n",
      "Iter:160 Test_Accuracy: 0.818 Train_Accuracy: 0.925\n",
      "Iter:170 Test_Accuracy: 0.8205 Train_Accuracy: 0.917\n",
      "Iter:180 Test_Accuracy: 0.8225 Train_Accuracy: 0.921\n",
      "Iter:190 Test_Accuracy: 0.8235 Train_Accuracy: 0.919\n",
      "Iter:200 Test_Accuracy: 0.823 Train_Accuracy: 0.928\n",
      "Iter:210 Test_Accuracy: 0.823 Train_Accuracy: 0.934\n",
      "Iter:220 Test_Accuracy: 0.8255 Train_Accuracy: 0.934\n",
      "Iter:230 Test_Accuracy: 0.826 Train_Accuracy: 0.935\n",
      "Iter:240 Test_Accuracy: 0.824 Train_Accuracy: 0.937\n",
      "Iter:250 Test_Accuracy: 0.8265 Train_Accuracy: 0.945\n",
      "Iter:260 Test_Accuracy: 0.827 Train_Accuracy: 0.949\n",
      "Iter:270 Test_Accuracy: 0.8305 Train_Accuracy: 0.943\n",
      "Iter:280 Test_Accuracy: 0.8305 Train_Accuracy: 0.947\n",
      "Iter:290 Test_Accuracy: 0.8305 Train_Accuracy: 0.952\n",
      "Iter:300 Test_Accuracy: 0.8345 Train_Accuracy: 0.941\n"
     ]
    }
   ],
   "source": [
    "images, labels = x_train[:1000].reshape(1000, 28*28)/255 , y_train[:1000] # загружаем 1000 изображений и меток (train)\n",
    "one_hot_labels = np.zeros((1000, 10)) # готовим нулевую матрицу. По строкам обучающие примеры, по столбцам метка\n",
    "for n,l in enumerate(labels):\n",
    "    one_hot_labels[n,l] = 1 # для каждой строки в одном из столбцов ставим 1, соответствующую метке (train)\n",
    "labels = one_hot_labels # переопределяем labels\n",
    "\n",
    "test_images, test_labels = x_test.reshape(-1, 28*28)/255, y_test # загружаем 1000 изображений и меток (test)\n",
    "one_hot_labels_test = np.zeros((x_test.shape[0], 10)) # готовим нулевую матрицу. По строкам обучающие примеры, по столбцам метка\n",
    "for n, l in enumerate(test_labels): # для каждой строки в одном из столбцов ставим 1, соответствующую метке (test)\n",
    "    one_hot_labels_test[n,l] = 1\n",
    "test_labels = one_hot_labels_test\n",
    "\n",
    "\n",
    "tanh = lambda x: np.tanh(x)\n",
    "tanh2deriv = lambda output: 1 - (output ** 2)\n",
    "softmax = lambda x: np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "    \n",
    "# relu = lambda x: (x>=0)*x # пишем лямбда-функцию relu (обнуляет отрицательные веса)\n",
    "# relu2deriv = lambda x: x >= 0 # пишем лямбда-функцию relu2deriv (обнуляет отрицательные нейроны)\n",
    "\n",
    "# устанавливаем параметры\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (2, 301, 100, 784, 10)\n",
    "batch_size = 100\n",
    "\n",
    "# инициализируем случайные веса\n",
    "weights_0_1 = 0.02*np.random.random((pixels_per_image, hidden_size)) - 0.01 # для слоя 1, форма (784, 100)\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1 # для слоя 2, форма (100, 10)\n",
    "\n",
    "for j in range(iterations): # итерируемся\n",
    "#     error, correct_cnt = (0.0, 0) # error - RSE, correct_cnt - количество True-Positive ответов\n",
    "    correct_cnt = 0\n",
    "    for i in range(round(images.shape[0]/batch_size)): # бежим по обучающим примерам\n",
    "        batch_start, batch_end = ((i * batch_size),((i+1) * batch_size)) # 0-99, 100-199 ...\n",
    "        layer_0 = images[batch_start:batch_end,:].reshape(batch_size,pixels_per_image) # подаем на входной слой изображение (100,784)\n",
    "        layer_1 = tanh(layer_0.dot(weights_0_1)).reshape(batch_size,batch_size) # скалярное перемножение входного слоя (100,784) на веса (784,100), \n",
    "                                                # получаем (100,100), затем применяем relu для обнуления нейронов с отриц. знач.\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape) # создаем маску вида array([[0, 1, 0, ... 0, 0, 1]]),\n",
    "                                                                # где вероятность единиц и нулей по 50% (100,100)\n",
    "        layer_1 *= dropout_mask * 2 # применяем маску, но умноженную на 2 \n",
    "                        # (т.к. сигнал от слоя 1 примерно в 2 раза уменьшается после применения маски, поэтому его нужно усилить)\n",
    "        \n",
    "        layer_2 = softmax(layer_1.dot(weights_1_2).reshape(batch_size,num_labels)) # скалярное перемножение внутреннего слоя (100,100) на веса (100,10), \n",
    "                                            # получаем выходной слой (100,10) с вероятностями каждого лейбла.\n",
    "        \n",
    "#         error += np.sum((layer_2 - labels[batch_start:batch_end,:])**2) # учитываем ошибку по i-тому обучающему примеру \n",
    "#                                                         # в общей ошибке для j-той итерации\n",
    "#         print(error)\n",
    "        for k in range(batch_size): # итерируемся по примерам в батче\n",
    "            correct_cnt += int(np.argmax(layer_2[k,:]) == np.argmax(labels[batch_start+k,:])) # учитываем True-Positive ответ (если есть)\n",
    "                                                                                # в общем показателей correct_cnt для j-той итерации\n",
    "        layer_2_delta = (layer_2 - labels[batch_start:batch_end,:])/\\\n",
    "                                            (batch_size * layer_2.shape[0]) # считаем отклонение по выходному слою (100,10)\n",
    "        #print(layer_2_delta.shape)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1) # считаем отклонение по среднему слою:\n",
    "                                                        # скалярно перемножаем отклонение по выходному слою (100,10)\n",
    "                                                        # на транспонированную матрицу весов weights_1_2 (10,100)\n",
    "                                                        # получаем вектор (100,100)\n",
    "        layer_1_delta *= dropout_mask # при обратном распространении корректировать обнуленные маской нейроны не следует\n",
    "                                        # поэтому той же маской обнуляем полученные дельты\n",
    "\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta) # корректируем веса для выходного слоя: \n",
    "                                                            # из матрицы текущих весов (100,10) вычитаем\n",
    "                                                            # помноженный на скорость обучения слой 1 транспонированный (100,100)\n",
    "                                                            # скалярно умножаем на отклонение по слою 2 (100,10)\n",
    "                                                            # получаем (100,10) - такой же формы, как и были наши веса weights_1_2\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta) # корректируем веса для скрытого слоя: \n",
    "                                                            # из матрицы текущих весов (784, 100) вычитаем\n",
    "                                                            # помноженный на скорость обучения слой 0 транспонированный (784,100)\n",
    "                                                            # скалярно умножаем на отклонение по слою 1 (100,100)\n",
    "\n",
    "                                                            # получаем (784,100) - такой же формы, как и были наши веса weights_0_1\n",
    "        \n",
    "    test_correct_cnt = 0 # correct_cnt - количество True-Positive ответов\n",
    "\n",
    "    for i in range(test_images.shape[0]): # бежим по обучающим примерам\n",
    "        layer_0 = test_images[i,:].reshape(1,-1) # подаем на входной слой изображение (1,784)\n",
    "        layer_1 = tanh(layer_0.dot(weights_0_1)).reshape(1,-1) # скалярное перемножение входного слоя (1,784) на веса (784,40), \n",
    "                                                # получаем (1,40), затем применяем relu для обнуления нейронов с отриц. знач.\n",
    "        layer_2 = layer_1.dot(weights_1_2).reshape(1,-1) # скалярное перемножение внутреннего слоя (1,40) на веса (40,10), \n",
    "                                            # получаем выходной слой (1,10) с вероятностями каждого лейбла.\n",
    "        \n",
    "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i,:])) # учитываем True-Positive ответ (если есть)\n",
    "                                                                            # в общем показателей correct_cnt для j-той итерации\n",
    "    if j % 10 == 0:\n",
    "        print(\"Iter:\" + str(j) +\\\n",
    "             \" Test_Accuracy: \" + str(test_correct_cnt/float(test_images.shape[0])) +\\\n",
    "              \" Train_Accuracy: \" + str(correct_cnt/float(images.shape[0])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сверточная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_section(layer, row_from, row_to, col_from, col_to):\n",
    "    '''Функция выбирает подобласть в изображении'''\n",
    "    sub_section = layer[:, row_from:row_to, col_from:col_to]\n",
    "    return sub_section.reshape(-1, 1, row_to - row_from, col_to - col_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11, 12, 13, 14, 15],\n",
       "       [16, 17, 18, 19, 20, 21, 22, 23],\n",
       "       [24, 25, 26, 27, 28, 29, 30, 31],\n",
       "       [32, 33, 34, 35, 36, 37, 38, 39],\n",
       "       [40, 41, 42, 43, 44, 45, 46, 47],\n",
       "       [48, 49, 50, 51, 52, 53, 54, 55],\n",
       "       [56, 57, 58, 59, 60, 61, 62, 63]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.arange(64).reshape(8,8)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8, 8)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([aa]*3)\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 1],\n",
       "         [8, 9]]],\n",
       "\n",
       "\n",
       "       [[[0, 1],\n",
       "         [8, 9]]],\n",
       "\n",
       "\n",
       "       [[[0, 1],\n",
       "         [8, 9]]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_section(aa, 0, 2, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1, 2, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_section(aa, 0, 2, 0, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sects 676\n",
      "expanded_input (104, 676, 3, 3)\n",
      "es (104, 676, 3, 3)\n",
      "flattened_input (70304, 9)\n"
     ]
    }
   ],
   "source": [
    "# проверим функцию\n",
    "layer_0 = images[batch_start:batch_end] # (100, 784)\n",
    "layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28) # (100, 28, 28)\n",
    "\n",
    "sects = []\n",
    "kernel_rows, kernel_cols = (3, 3)\n",
    "\n",
    "for row_start in range(layer_0.shape[1] - kernel_rows + 1): # бежим по строкам от 0 до 28-3 включительно\n",
    "    for col_start in range(layer_0.shape[2] - kernel_cols + 1): # бежим по столбцам от 0 до 28-3 включительно\n",
    "        sect = get_image_section(layer_0,\n",
    "                                row_start, # будет перебираться от 0 до 25 включительно\n",
    "                                row_start + kernel_rows, # будет перебираться от 3 до 28 включительно\n",
    "                                col_start, # будет перебираться от 0 до 25 включительно\n",
    "                                col_start + kernel_cols) # будет перебираться от 3 до 28 включительно\n",
    "        sects.append(sect) # всего д.б. 26*26 = 676 массивов размера (100, 1, 3, 3)\n",
    "print(f'sects {len(sects)}')       \n",
    "expanded_input = np.concatenate(sects, axis=1) # соединяем массивы горизонтально (присоединяем справа) получаем (100, 676, 3, 3)\n",
    "print(f'expanded_input {expanded_input.shape}')\n",
    "es = expanded_input.shape # (100, 676, 3, 3) большой столб, составленный из столбиков 3 на 3\n",
    "print(f'es {es}')\n",
    "flattened_input = expanded_input.reshape(es[0]*es[1], -1) # каждый \"плитку\" 3 на 3 вытягиваем в строку, транспонируем и выстраиваем в ряд\n",
    "# получаем (67600, 9)\n",
    "print(f'flattened_input {flattened_input.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полная реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 16)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_kernels = 16 # сделаем 16 разных ядер с рандомными весами от 0 до 1 (которые входят в эти ядра)\n",
    "kernels = np.random.random((kernel_rows*kernel_cols, num_kernels)) # делаем матрицу с весами для 16 ядер\n",
    "kernels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54395304, 0.77476367, 0.55578024, 0.68876649, 0.4469488 ,\n",
       "       0.20733249, 0.38132192, 0.61622455, 0.8077445 , 0.30486368,\n",
       "       0.97329327, 0.61889835, 0.44806278, 0.26944556, 0.97266354,\n",
       "       0.3125513 ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70304, 16)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_output = flattened_input.dot(kernels)\n",
    "kernel_output.shape # тут получаем 16 прогнозов для каждой \"плитки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "import numpy as np, sys, time\n",
    "\n",
    "np.random.seed(1) # фиксируем псевдослучайный генератор случайных чисел\n",
    "\n",
    "x_train = mnist.train_images()[:1000,:,:]\n",
    "y_train = mnist.train_labels()[:1000,...]\n",
    "\n",
    "x_test = mnist.test_images()[:2000,:,:]\n",
    "y_test = mnist.test_labels()[:2000,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:0 Test_Accuracy: 0.228 Train_Accuracy: 0.153 time: 13.0625seconds\n",
      "Iter:1 Test_Accuracy: 0.245 Train_Accuracy: 0.18 time: 13.703125seconds\n",
      "Iter:2 Test_Accuracy: 0.302 Train_Accuracy: 0.224 time: 13.640625seconds\n",
      "Iter:3 Test_Accuracy: 0.3735 Train_Accuracy: 0.239 time: 12.71875seconds\n",
      "Iter:4 Test_Accuracy: 0.456 Train_Accuracy: 0.301 time: 11.734375seconds\n",
      "Iter:5 Test_Accuracy: 0.5405 Train_Accuracy: 0.359 time: 13.015625seconds\n",
      "Iter:6 Test_Accuracy: 0.5945 Train_Accuracy: 0.409 time: 12.484375seconds\n",
      "Iter:7 Test_Accuracy: 0.6255 Train_Accuracy: 0.472 time: 12.578125seconds\n",
      "Iter:8 Test_Accuracy: 0.6465 Train_Accuracy: 0.529 time: 12.375seconds\n",
      "Iter:9 Test_Accuracy: 0.6645 Train_Accuracy: 0.595 time: 13.25seconds\n",
      "Iter:10 Test_Accuracy: 0.676 Train_Accuracy: 0.607 time: 14.234375seconds\n",
      "Iter:11 Test_Accuracy: 0.6925 Train_Accuracy: 0.64 time: 13.96875seconds\n",
      "Iter:12 Test_Accuracy: 0.704 Train_Accuracy: 0.682 time: 14.546875seconds\n",
      "Iter:13 Test_Accuracy: 0.7125 Train_Accuracy: 0.69 time: 14.140625seconds\n",
      "Iter:14 Test_Accuracy: 0.7205 Train_Accuracy: 0.71 time: 13.828125seconds\n",
      "Iter:15 Test_Accuracy: 0.726 Train_Accuracy: 0.695 time: 12.28125seconds\n",
      "Iter:16 Test_Accuracy: 0.7355 Train_Accuracy: 0.738 time: 12.53125seconds\n",
      "Iter:17 Test_Accuracy: 0.7405 Train_Accuracy: 0.74 time: 12.703125seconds\n",
      "Iter:18 Test_Accuracy: 0.744 Train_Accuracy: 0.741 time: 12.3125seconds\n",
      "Iter:19 Test_Accuracy: 0.747 Train_Accuracy: 0.748 time: 12.53125seconds\n",
      "Iter:20 Test_Accuracy: 0.7535 Train_Accuracy: 0.756 time: 12.90625seconds\n",
      "Iter:21 Test_Accuracy: 0.754 Train_Accuracy: 0.779 time: 12.328125seconds\n",
      "Iter:22 Test_Accuracy: 0.762 Train_Accuracy: 0.789 time: 12.515625seconds\n",
      "Iter:23 Test_Accuracy: 0.7665 Train_Accuracy: 0.783 time: 11.328125seconds\n",
      "Iter:24 Test_Accuracy: 0.768 Train_Accuracy: 0.797 time: 12.75seconds\n",
      "Iter:25 Test_Accuracy: 0.7775 Train_Accuracy: 0.807 time: 12.15625seconds\n",
      "Iter:26 Test_Accuracy: 0.7785 Train_Accuracy: 0.787 time: 12.5seconds\n",
      "Iter:27 Test_Accuracy: 0.7795 Train_Accuracy: 0.792 time: 14.15625seconds\n",
      "Iter:28 Test_Accuracy: 0.7785 Train_Accuracy: 0.81 time: 14.390625seconds\n",
      "Iter:29 Test_Accuracy: 0.783 Train_Accuracy: 0.812 time: 13.875seconds\n",
      "Iter:30 Test_Accuracy: 0.7845 Train_Accuracy: 0.818 time: 14.21875seconds\n",
      "Iter:31 Test_Accuracy: 0.789 Train_Accuracy: 0.815 time: 13.671875seconds\n",
      "Iter:32 Test_Accuracy: 0.793 Train_Accuracy: 0.83 time: 13.296875seconds\n",
      "Iter:33 Test_Accuracy: 0.7875 Train_Accuracy: 0.817 time: 10.765625seconds\n",
      "Iter:34 Test_Accuracy: 0.796 Train_Accuracy: 0.817 time: 12.71875seconds\n",
      "Iter:35 Test_Accuracy: 0.795 Train_Accuracy: 0.824 time: 12.359375seconds\n",
      "Iter:36 Test_Accuracy: 0.797 Train_Accuracy: 0.834 time: 12.3125seconds\n",
      "Iter:37 Test_Accuracy: 0.798 Train_Accuracy: 0.835 time: 12.453125seconds\n",
      "Iter:38 Test_Accuracy: 0.7955 Train_Accuracy: 0.832 time: 11.140625seconds\n",
      "Iter:39 Test_Accuracy: 0.799 Train_Accuracy: 0.837 time: 14.40625seconds\n",
      "Iter:40 Test_Accuracy: 0.801 Train_Accuracy: 0.831 time: 14.578125seconds\n",
      "Iter:41 Test_Accuracy: 0.7965 Train_Accuracy: 0.828 time: 13.703125seconds\n",
      "Iter:42 Test_Accuracy: 0.8015 Train_Accuracy: 0.839 time: 13.0625seconds\n",
      "Iter:43 Test_Accuracy: 0.7985 Train_Accuracy: 0.85 time: 14.390625seconds\n",
      "Iter:44 Test_Accuracy: 0.802 Train_Accuracy: 0.838 time: 13.890625seconds\n",
      "Iter:45 Test_Accuracy: 0.804 Train_Accuracy: 0.842 time: 14.53125seconds\n",
      "Iter:46 Test_Accuracy: 0.8015 Train_Accuracy: 0.848 time: 14.234375seconds\n",
      "Iter:47 Test_Accuracy: 0.805 Train_Accuracy: 0.85 time: 13.921875seconds\n",
      "Iter:48 Test_Accuracy: 0.8065 Train_Accuracy: 0.854 time: 12.6875seconds\n",
      "Iter:49 Test_Accuracy: 0.805 Train_Accuracy: 0.852 time: 12.40625seconds\n",
      "Iter:50 Test_Accuracy: 0.808 Train_Accuracy: 0.856 time: 12.546875seconds\n",
      "Iter:51 Test_Accuracy: 0.81 Train_Accuracy: 0.854 time: 13.34375seconds\n",
      "Iter:52 Test_Accuracy: 0.8095 Train_Accuracy: 0.848 time: 12.921875seconds\n",
      "Iter:53 Test_Accuracy: 0.81 Train_Accuracy: 0.86 time: 14.734375seconds\n",
      "Iter:54 Test_Accuracy: 0.806 Train_Accuracy: 0.868 time: 12.515625seconds\n",
      "Iter:55 Test_Accuracy: 0.807 Train_Accuracy: 0.865 time: 12.359375seconds\n",
      "Iter:56 Test_Accuracy: 0.81 Train_Accuracy: 0.868 time: 12.609375seconds\n",
      "Iter:57 Test_Accuracy: 0.8125 Train_Accuracy: 0.865 time: 13.640625seconds\n",
      "Iter:58 Test_Accuracy: 0.814 Train_Accuracy: 0.868 time: 13.46875seconds\n",
      "Iter:59 Test_Accuracy: 0.811 Train_Accuracy: 0.862 time: 14.359375seconds\n",
      "Iter:60 Test_Accuracy: 0.813 Train_Accuracy: 0.86 time: 13.96875seconds\n",
      "Iter:61 Test_Accuracy: 0.818 Train_Accuracy: 0.864 time: 14.28125seconds\n",
      "Iter:62 Test_Accuracy: 0.8175 Train_Accuracy: 0.862 time: 14.171875seconds\n",
      "Iter:63 Test_Accuracy: 0.8175 Train_Accuracy: 0.858 time: 14.671875seconds\n",
      "Iter:64 Test_Accuracy: 0.817 Train_Accuracy: 0.877 time: 14.234375seconds\n",
      "Iter:65 Test_Accuracy: 0.819 Train_Accuracy: 0.874 time: 12.5seconds\n",
      "Iter:66 Test_Accuracy: 0.8185 Train_Accuracy: 0.864 time: 12.578125seconds\n",
      "Iter:67 Test_Accuracy: 0.821 Train_Accuracy: 0.879 time: 12.65625seconds\n",
      "Iter:68 Test_Accuracy: 0.8215 Train_Accuracy: 0.877 time: 12.453125seconds\n",
      "Iter:69 Test_Accuracy: 0.8215 Train_Accuracy: 0.879 time: 13.3125seconds\n",
      "Iter:70 Test_Accuracy: 0.8205 Train_Accuracy: 0.86 time: 12.296875seconds\n",
      "Iter:71 Test_Accuracy: 0.8255 Train_Accuracy: 0.881 time: 13.03125seconds\n",
      "Iter:72 Test_Accuracy: 0.825 Train_Accuracy: 0.869 time: 12.515625seconds\n",
      "Iter:73 Test_Accuracy: 0.8225 Train_Accuracy: 0.878 time: 12.8125seconds\n",
      "Iter:74 Test_Accuracy: 0.8245 Train_Accuracy: 0.881 time: 12.9375seconds\n",
      "Iter:75 Test_Accuracy: 0.8245 Train_Accuracy: 0.88 time: 12.5seconds\n",
      "Iter:76 Test_Accuracy: 0.827 Train_Accuracy: 0.877 time: 13.6875seconds\n",
      "Iter:77 Test_Accuracy: 0.824 Train_Accuracy: 0.881 time: 14.34375seconds\n",
      "Iter:78 Test_Accuracy: 0.828 Train_Accuracy: 0.88 time: 14.109375seconds\n",
      "Iter:79 Test_Accuracy: 0.826 Train_Accuracy: 0.881 time: 14.03125seconds\n",
      "Iter:80 Test_Accuracy: 0.8285 Train_Accuracy: 0.882 time: 13.546875seconds\n",
      "Iter:81 Test_Accuracy: 0.832 Train_Accuracy: 0.88 time: 13.1875seconds\n",
      "Iter:82 Test_Accuracy: 0.8335 Train_Accuracy: 0.886 time: 13.375seconds\n",
      "Iter:83 Test_Accuracy: 0.831 Train_Accuracy: 0.879 time: 13.03125seconds\n",
      "Iter:84 Test_Accuracy: 0.8345 Train_Accuracy: 0.877 time: 13.09375seconds\n",
      "Iter:85 Test_Accuracy: 0.8325 Train_Accuracy: 0.891 time: 13.15625seconds\n",
      "Iter:86 Test_Accuracy: 0.8355 Train_Accuracy: 0.889 time: 12.765625seconds\n",
      "Iter:87 Test_Accuracy: 0.833 Train_Accuracy: 0.892 time: 13.515625seconds\n",
      "Iter:88 Test_Accuracy: 0.834 Train_Accuracy: 0.884 time: 12.28125seconds\n",
      "Iter:89 Test_Accuracy: 0.8365 Train_Accuracy: 0.883 time: 13.140625seconds\n",
      "Iter:90 Test_Accuracy: 0.8345 Train_Accuracy: 0.894 time: 13.15625seconds\n",
      "Iter:91 Test_Accuracy: 0.831 Train_Accuracy: 0.881 time: 13.421875seconds\n",
      "Iter:92 Test_Accuracy: 0.834 Train_Accuracy: 0.903 time: 13.703125seconds\n",
      "Iter:93 Test_Accuracy: 0.831 Train_Accuracy: 0.901 time: 14.484375seconds\n",
      "Iter:94 Test_Accuracy: 0.8305 Train_Accuracy: 0.899 time: 13.359375seconds\n",
      "Iter:95 Test_Accuracy: 0.831 Train_Accuracy: 0.887 time: 14.40625seconds\n",
      "Iter:96 Test_Accuracy: 0.834 Train_Accuracy: 0.893 time: 13.953125seconds\n",
      "Iter:97 Test_Accuracy: 0.835 Train_Accuracy: 0.892 time: 14.15625seconds\n",
      "Iter:98 Test_Accuracy: 0.831 Train_Accuracy: 0.9 time: 13.546875seconds\n",
      "Iter:99 Test_Accuracy: 0.8315 Train_Accuracy: 0.892 time: 12.359375seconds\n",
      "Iter:100 Test_Accuracy: 0.8325 Train_Accuracy: 0.913 time: 13.125seconds\n",
      "Iter:101 Test_Accuracy: 0.8325 Train_Accuracy: 0.888 time: 12.578125seconds\n",
      "Iter:102 Test_Accuracy: 0.833 Train_Accuracy: 0.892 time: 13.0seconds\n",
      "Iter:103 Test_Accuracy: 0.8345 Train_Accuracy: 0.893 time: 13.0seconds\n",
      "Iter:104 Test_Accuracy: 0.8345 Train_Accuracy: 0.901 time: 12.28125seconds\n",
      "Iter:105 Test_Accuracy: 0.8345 Train_Accuracy: 0.907 time: 12.890625seconds\n",
      "Iter:106 Test_Accuracy: 0.8345 Train_Accuracy: 0.903 time: 12.46875seconds\n",
      "Iter:107 Test_Accuracy: 0.835 Train_Accuracy: 0.893 time: 12.6875seconds\n",
      "Iter:108 Test_Accuracy: 0.834 Train_Accuracy: 0.896 time: 13.21875seconds\n",
      "Iter:109 Test_Accuracy: 0.8365 Train_Accuracy: 0.897 time: 13.109375seconds\n",
      "Iter:110 Test_Accuracy: 0.8355 Train_Accuracy: 0.907 time: 14.3125seconds\n",
      "Iter:111 Test_Accuracy: 0.836 Train_Accuracy: 0.9 time: 13.84375seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:112 Test_Accuracy: 0.8365 Train_Accuracy: 0.905 time: 14.640625seconds\n",
      "Iter:113 Test_Accuracy: 0.835 Train_Accuracy: 0.895 time: 14.078125seconds\n",
      "Iter:114 Test_Accuracy: 0.8345 Train_Accuracy: 0.905 time: 14.046875seconds\n",
      "Iter:115 Test_Accuracy: 0.8345 Train_Accuracy: 0.912 time: 12.796875seconds\n",
      "Iter:116 Test_Accuracy: 0.8355 Train_Accuracy: 0.902 time: 13.109375seconds\n",
      "Iter:117 Test_Accuracy: 0.8355 Train_Accuracy: 0.907 time: 12.515625seconds\n",
      "Iter:118 Test_Accuracy: 0.836 Train_Accuracy: 0.905 time: 13.015625seconds\n",
      "Iter:119 Test_Accuracy: 0.836 Train_Accuracy: 0.91 time: 12.84375seconds\n",
      "Iter:120 Test_Accuracy: 0.837 Train_Accuracy: 0.904 time: 13.015625seconds\n",
      "Iter:121 Test_Accuracy: 0.838 Train_Accuracy: 0.912 time: 12.546875seconds\n",
      "Iter:122 Test_Accuracy: 0.836 Train_Accuracy: 0.895 time: 12.453125seconds\n",
      "Iter:123 Test_Accuracy: 0.8365 Train_Accuracy: 0.9 time: 13.21875seconds\n",
      "Iter:124 Test_Accuracy: 0.837 Train_Accuracy: 0.909 time: 12.84375seconds\n",
      "Iter:125 Test_Accuracy: 0.837 Train_Accuracy: 0.911 time: 13.25seconds\n",
      "Iter:126 Test_Accuracy: 0.838 Train_Accuracy: 0.903 time: 13.6875seconds\n",
      "Iter:127 Test_Accuracy: 0.8375 Train_Accuracy: 0.914 time: 14.296875seconds\n",
      "Iter:128 Test_Accuracy: 0.8385 Train_Accuracy: 0.911 time: 14.640625seconds\n",
      "Iter:129 Test_Accuracy: 0.84 Train_Accuracy: 0.911 time: 14.171875seconds\n",
      "Iter:130 Test_Accuracy: 0.8405 Train_Accuracy: 0.916 time: 14.703125seconds\n",
      "Iter:131 Test_Accuracy: 0.8385 Train_Accuracy: 0.913 time: 13.984375seconds\n",
      "Iter:132 Test_Accuracy: 0.8385 Train_Accuracy: 0.909 time: 12.96875seconds\n",
      "Iter:133 Test_Accuracy: 0.839 Train_Accuracy: 0.908 time: 12.5625seconds\n",
      "Iter:134 Test_Accuracy: 0.839 Train_Accuracy: 0.907 time: 14.03125seconds\n",
      "Iter:135 Test_Accuracy: 0.8395 Train_Accuracy: 0.907 time: 12.328125seconds\n",
      "Iter:136 Test_Accuracy: 0.8365 Train_Accuracy: 0.907 time: 13.453125seconds\n",
      "Iter:137 Test_Accuracy: 0.835 Train_Accuracy: 0.908 time: 12.296875seconds\n",
      "Iter:138 Test_Accuracy: 0.833 Train_Accuracy: 0.907 time: 13.171875seconds\n",
      "Iter:139 Test_Accuracy: 0.835 Train_Accuracy: 0.913 time: 12.1875seconds\n",
      "Iter:140 Test_Accuracy: 0.8385 Train_Accuracy: 0.914 time: 12.515625seconds\n",
      "Iter:141 Test_Accuracy: 0.837 Train_Accuracy: 0.922 time: 12.71875seconds\n",
      "Iter:142 Test_Accuracy: 0.8385 Train_Accuracy: 0.914 time: 13.125seconds\n",
      "Iter:143 Test_Accuracy: 0.8365 Train_Accuracy: 0.911 time: 13.640625seconds\n",
      "Iter:144 Test_Accuracy: 0.836 Train_Accuracy: 0.918 time: 14.359375seconds\n",
      "Iter:145 Test_Accuracy: 0.837 Train_Accuracy: 0.907 time: 13.96875seconds\n",
      "Iter:146 Test_Accuracy: 0.837 Train_Accuracy: 0.909 time: 14.546875seconds\n",
      "Iter:147 Test_Accuracy: 0.839 Train_Accuracy: 0.919 time: 13.078125seconds\n",
      "Iter:148 Test_Accuracy: 0.838 Train_Accuracy: 0.918 time: 12.734375seconds\n",
      "Iter:149 Test_Accuracy: 0.837 Train_Accuracy: 0.909 time: 13.40625seconds\n",
      "Iter:150 Test_Accuracy: 0.8395 Train_Accuracy: 0.916 time: 12.359375seconds\n",
      "Iter:151 Test_Accuracy: 0.839 Train_Accuracy: 0.913 time: 13.15625seconds\n",
      "Iter:152 Test_Accuracy: 0.8395 Train_Accuracy: 0.922 time: 12.5625seconds\n",
      "Iter:153 Test_Accuracy: 0.838 Train_Accuracy: 0.92 time: 12.53125seconds\n",
      "Iter:154 Test_Accuracy: 0.8385 Train_Accuracy: 0.93 time: 13.421875seconds\n",
      "Iter:155 Test_Accuracy: 0.837 Train_Accuracy: 0.916 time: 12.390625seconds\n",
      "Iter:156 Test_Accuracy: 0.8365 Train_Accuracy: 0.909 time: 13.265625seconds\n",
      "Iter:157 Test_Accuracy: 0.836 Train_Accuracy: 0.926 time: 12.734375seconds\n",
      "Iter:158 Test_Accuracy: 0.8375 Train_Accuracy: 0.912 time: 12.46875seconds\n",
      "Iter:159 Test_Accuracy: 0.836 Train_Accuracy: 0.916 time: 13.265625seconds\n",
      "Iter:160 Test_Accuracy: 0.8365 Train_Accuracy: 0.915 time: 14.171875seconds\n",
      "Iter:161 Test_Accuracy: 0.839 Train_Accuracy: 0.915 time: 14.03125seconds\n",
      "Iter:162 Test_Accuracy: 0.838 Train_Accuracy: 0.925 time: 14.390625seconds\n",
      "Iter:163 Test_Accuracy: 0.839 Train_Accuracy: 0.92 time: 13.609375seconds\n",
      "Iter:164 Test_Accuracy: 0.8385 Train_Accuracy: 0.925 time: 14.140625seconds\n",
      "Iter:165 Test_Accuracy: 0.8375 Train_Accuracy: 0.927 time: 13.609375seconds\n",
      "Iter:166 Test_Accuracy: 0.838 Train_Accuracy: 0.925 time: 13.046875seconds\n",
      "Iter:167 Test_Accuracy: 0.837 Train_Accuracy: 0.924 time: 13.390625seconds\n",
      "Iter:168 Test_Accuracy: 0.8395 Train_Accuracy: 0.922 time: 12.171875seconds\n",
      "Iter:169 Test_Accuracy: 0.8375 Train_Accuracy: 0.923 time: 12.59375seconds\n",
      "Iter:170 Test_Accuracy: 0.838 Train_Accuracy: 0.911 time: 12.78125seconds\n",
      "Iter:171 Test_Accuracy: 0.838 Train_Accuracy: 0.931 time: 12.546875seconds\n",
      "Iter:172 Test_Accuracy: 0.8395 Train_Accuracy: 0.939 time: 13.265625seconds\n",
      "Iter:173 Test_Accuracy: 0.8405 Train_Accuracy: 0.924 time: 12.296875seconds\n",
      "Iter:174 Test_Accuracy: 0.8395 Train_Accuracy: 0.929 time: 12.734375seconds\n",
      "Iter:175 Test_Accuracy: 0.8375 Train_Accuracy: 0.911 time: 12.765625seconds\n",
      "Iter:176 Test_Accuracy: 0.839 Train_Accuracy: 0.92 time: 13.09375seconds\n",
      "Iter:177 Test_Accuracy: 0.84 Train_Accuracy: 0.93 time: 13.75seconds\n",
      "Iter:178 Test_Accuracy: 0.838 Train_Accuracy: 0.924 time: 14.28125seconds\n",
      "Iter:179 Test_Accuracy: 0.8395 Train_Accuracy: 0.928 time: 14.171875seconds\n",
      "Iter:180 Test_Accuracy: 0.8375 Train_Accuracy: 0.927 time: 14.453125seconds\n",
      "Iter:181 Test_Accuracy: 0.839 Train_Accuracy: 0.917 time: 14.109375seconds\n",
      "Iter:182 Test_Accuracy: 0.8385 Train_Accuracy: 0.917 time: 12.546875seconds\n",
      "Iter:183 Test_Accuracy: 0.839 Train_Accuracy: 0.928 time: 10.703125seconds\n",
      "Iter:184 Test_Accuracy: 0.8365 Train_Accuracy: 0.918 time: 10.3125seconds\n",
      "Iter:185 Test_Accuracy: 0.839 Train_Accuracy: 0.925 time: 10.21875seconds\n",
      "Iter:186 Test_Accuracy: 0.8365 Train_Accuracy: 0.924 time: 10.453125seconds\n",
      "Iter:187 Test_Accuracy: 0.8365 Train_Accuracy: 0.931 time: 10.171875seconds\n",
      "Iter:188 Test_Accuracy: 0.839 Train_Accuracy: 0.925 time: 10.3125seconds\n",
      "Iter:189 Test_Accuracy: 0.837 Train_Accuracy: 0.928 time: 9.859375seconds\n",
      "Iter:190 Test_Accuracy: 0.8345 Train_Accuracy: 0.932 time: 10.515625seconds\n",
      "Iter:191 Test_Accuracy: 0.8355 Train_Accuracy: 0.932 time: 10.328125seconds\n",
      "Iter:192 Test_Accuracy: 0.8355 Train_Accuracy: 0.936 time: 10.171875seconds\n",
      "Iter:193 Test_Accuracy: 0.836 Train_Accuracy: 0.928 time: 10.828125seconds\n",
      "Iter:194 Test_Accuracy: 0.8375 Train_Accuracy: 0.923 time: 10.390625seconds\n",
      "Iter:195 Test_Accuracy: 0.8375 Train_Accuracy: 0.931 time: 10.171875seconds\n",
      "Iter:196 Test_Accuracy: 0.836 Train_Accuracy: 0.929 time: 10.515625seconds\n",
      "Iter:197 Test_Accuracy: 0.8375 Train_Accuracy: 0.942 time: 11.171875seconds\n",
      "Iter:198 Test_Accuracy: 0.8385 Train_Accuracy: 0.934 time: 11.8125seconds\n",
      "Iter:199 Test_Accuracy: 0.837 Train_Accuracy: 0.928 time: 12.71875seconds\n",
      "Iter:200 Test_Accuracy: 0.8385 Train_Accuracy: 0.933 time: 11.265625seconds\n",
      "Iter:201 Test_Accuracy: 0.8345 Train_Accuracy: 0.929 time: 11.546875seconds\n",
      "Iter:202 Test_Accuracy: 0.838 Train_Accuracy: 0.937 time: 14.34375seconds\n",
      "Iter:203 Test_Accuracy: 0.836 Train_Accuracy: 0.926 time: 14.15625seconds\n",
      "Iter:204 Test_Accuracy: 0.836 Train_Accuracy: 0.933 time: 13.984375seconds\n",
      "Iter:205 Test_Accuracy: 0.8385 Train_Accuracy: 0.934 time: 12.765625seconds\n",
      "Iter:206 Test_Accuracy: 0.8365 Train_Accuracy: 0.937 time: 12.625seconds\n",
      "Iter:207 Test_Accuracy: 0.839 Train_Accuracy: 0.937 time: 10.109375seconds\n",
      "Iter:208 Test_Accuracy: 0.839 Train_Accuracy: 0.938 time: 9.921875seconds\n",
      "Iter:209 Test_Accuracy: 0.837 Train_Accuracy: 0.935 time: 10.234375seconds\n",
      "Iter:210 Test_Accuracy: 0.838 Train_Accuracy: 0.926 time: 9.828125seconds\n",
      "Iter:211 Test_Accuracy: 0.8375 Train_Accuracy: 0.934 time: 9.828125seconds\n",
      "Iter:212 Test_Accuracy: 0.836 Train_Accuracy: 0.931 time: 9.53125seconds\n",
      "Iter:213 Test_Accuracy: 0.8375 Train_Accuracy: 0.924 time: 10.3125seconds\n",
      "Iter:214 Test_Accuracy: 0.8355 Train_Accuracy: 0.932 time: 9.65625seconds\n",
      "Iter:215 Test_Accuracy: 0.8355 Train_Accuracy: 0.94 time: 9.625seconds\n",
      "Iter:216 Test_Accuracy: 0.8375 Train_Accuracy: 0.938 time: 9.5seconds\n",
      "Iter:217 Test_Accuracy: 0.836 Train_Accuracy: 0.935 time: 10.234375seconds\n",
      "Iter:218 Test_Accuracy: 0.8365 Train_Accuracy: 0.935 time: 9.921875seconds\n",
      "Iter:219 Test_Accuracy: 0.8365 Train_Accuracy: 0.945 time: 10.1875seconds\n",
      "Iter:220 Test_Accuracy: 0.838 Train_Accuracy: 0.938 time: 10.28125seconds\n",
      "Iter:221 Test_Accuracy: 0.8365 Train_Accuracy: 0.939 time: 10.125seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:222 Test_Accuracy: 0.837 Train_Accuracy: 0.938 time: 10.1875seconds\n",
      "Iter:223 Test_Accuracy: 0.835 Train_Accuracy: 0.934 time: 10.28125seconds\n",
      "Iter:224 Test_Accuracy: 0.835 Train_Accuracy: 0.921 time: 9.921875seconds\n",
      "Iter:225 Test_Accuracy: 0.834 Train_Accuracy: 0.946 time: 9.84375seconds\n",
      "Iter:226 Test_Accuracy: 0.835 Train_Accuracy: 0.933 time: 10.03125seconds\n",
      "Iter:227 Test_Accuracy: 0.835 Train_Accuracy: 0.937 time: 9.703125seconds\n",
      "Iter:228 Test_Accuracy: 0.8325 Train_Accuracy: 0.936 time: 10.09375seconds\n",
      "Iter:229 Test_Accuracy: 0.8325 Train_Accuracy: 0.935 time: 10.046875seconds\n",
      "Iter:230 Test_Accuracy: 0.8365 Train_Accuracy: 0.938 time: 10.828125seconds\n",
      "Iter:231 Test_Accuracy: 0.8355 Train_Accuracy: 0.927 time: 10.0625seconds\n",
      "Iter:232 Test_Accuracy: 0.835 Train_Accuracy: 0.929 time: 10.328125seconds\n",
      "Iter:233 Test_Accuracy: 0.8355 Train_Accuracy: 0.941 time: 10.03125seconds\n",
      "Iter:234 Test_Accuracy: 0.833 Train_Accuracy: 0.94 time: 9.96875seconds\n",
      "Iter:235 Test_Accuracy: 0.8355 Train_Accuracy: 0.937 time: 11.328125seconds\n",
      "Iter:236 Test_Accuracy: 0.8375 Train_Accuracy: 0.94 time: 10.109375seconds\n",
      "Iter:237 Test_Accuracy: 0.8345 Train_Accuracy: 0.93 time: 10.328125seconds\n",
      "Iter:238 Test_Accuracy: 0.8365 Train_Accuracy: 0.937 time: 11.859375seconds\n",
      "Iter:239 Test_Accuracy: 0.835 Train_Accuracy: 0.938 time: 11.296875seconds\n",
      "Iter:240 Test_Accuracy: 0.836 Train_Accuracy: 0.947 time: 10.484375seconds\n",
      "Iter:241 Test_Accuracy: 0.8365 Train_Accuracy: 0.939 time: 10.875seconds\n",
      "Iter:242 Test_Accuracy: 0.835 Train_Accuracy: 0.944 time: 10.453125seconds\n",
      "Iter:243 Test_Accuracy: 0.8355 Train_Accuracy: 0.938 time: 10.8125seconds\n",
      "Iter:244 Test_Accuracy: 0.8365 Train_Accuracy: 0.937 time: 10.515625seconds\n",
      "Iter:245 Test_Accuracy: 0.836 Train_Accuracy: 0.936 time: 10.71875seconds\n",
      "Iter:246 Test_Accuracy: 0.8335 Train_Accuracy: 0.936 time: 11.171875seconds\n",
      "Iter:247 Test_Accuracy: 0.8315 Train_Accuracy: 0.937 time: 10.859375seconds\n",
      "Iter:248 Test_Accuracy: 0.835 Train_Accuracy: 0.939 time: 10.40625seconds\n",
      "Iter:249 Test_Accuracy: 0.8335 Train_Accuracy: 0.944 time: 9.546875seconds\n",
      "Iter:250 Test_Accuracy: 0.8345 Train_Accuracy: 0.936 time: 10.09375seconds\n",
      "Iter:251 Test_Accuracy: 0.8365 Train_Accuracy: 0.94 time: 12.484375seconds\n",
      "Iter:252 Test_Accuracy: 0.834 Train_Accuracy: 0.94 time: 13.09375seconds\n",
      "Iter:253 Test_Accuracy: 0.8355 Train_Accuracy: 0.952 time: 12.53125seconds\n",
      "Iter:254 Test_Accuracy: 0.834 Train_Accuracy: 0.941 time: 11.359375seconds\n",
      "Iter:255 Test_Accuracy: 0.835 Train_Accuracy: 0.934 time: 12.203125seconds\n",
      "Iter:256 Test_Accuracy: 0.835 Train_Accuracy: 0.931 time: 9.203125seconds\n",
      "Iter:257 Test_Accuracy: 0.8325 Train_Accuracy: 0.945 time: 9.203125seconds\n",
      "Iter:258 Test_Accuracy: 0.8345 Train_Accuracy: 0.939 time: 10.53125seconds\n",
      "Iter:259 Test_Accuracy: 0.834 Train_Accuracy: 0.94 time: 11.8125seconds\n",
      "Iter:260 Test_Accuracy: 0.8365 Train_Accuracy: 0.946 time: 15.171875seconds\n",
      "Iter:261 Test_Accuracy: 0.8345 Train_Accuracy: 0.938 time: 14.078125seconds\n",
      "Iter:262 Test_Accuracy: 0.833 Train_Accuracy: 0.948 time: 13.65625seconds\n",
      "Iter:263 Test_Accuracy: 0.8355 Train_Accuracy: 0.945 time: 13.59375seconds\n",
      "Iter:264 Test_Accuracy: 0.837 Train_Accuracy: 0.95 time: 13.109375seconds\n",
      "Iter:265 Test_Accuracy: 0.836 Train_Accuracy: 0.949 time: 14.015625seconds\n",
      "Iter:266 Test_Accuracy: 0.834 Train_Accuracy: 0.945 time: 12.375seconds\n",
      "Iter:267 Test_Accuracy: 0.835 Train_Accuracy: 0.944 time: 12.125seconds\n",
      "Iter:268 Test_Accuracy: 0.834 Train_Accuracy: 0.953 time: 13.78125seconds\n",
      "Iter:269 Test_Accuracy: 0.8355 Train_Accuracy: 0.944 time: 12.484375seconds\n",
      "Iter:270 Test_Accuracy: 0.8345 Train_Accuracy: 0.942 time: 10.453125seconds\n",
      "Iter:271 Test_Accuracy: 0.8355 Train_Accuracy: 0.947 time: 13.40625seconds\n",
      "Iter:272 Test_Accuracy: 0.836 Train_Accuracy: 0.951 time: 10.875seconds\n",
      "Iter:273 Test_Accuracy: 0.834 Train_Accuracy: 0.944 time: 10.03125seconds\n",
      "Iter:274 Test_Accuracy: 0.8325 Train_Accuracy: 0.944 time: 9.90625seconds\n",
      "Iter:275 Test_Accuracy: 0.8315 Train_Accuracy: 0.946 time: 9.578125seconds\n",
      "Iter:276 Test_Accuracy: 0.833 Train_Accuracy: 0.941 time: 8.890625seconds\n",
      "Iter:277 Test_Accuracy: 0.832 Train_Accuracy: 0.943 time: 9.25seconds\n",
      "Iter:278 Test_Accuracy: 0.833 Train_Accuracy: 0.942 time: 9.703125seconds\n",
      "Iter:279 Test_Accuracy: 0.831 Train_Accuracy: 0.948 time: 9.90625seconds\n",
      "Iter:280 Test_Accuracy: 0.832 Train_Accuracy: 0.949 time: 10.40625seconds\n",
      "Iter:281 Test_Accuracy: 0.833 Train_Accuracy: 0.941 time: 10.8125seconds\n",
      "Iter:282 Test_Accuracy: 0.8325 Train_Accuracy: 0.953 time: 10.4375seconds\n",
      "Iter:283 Test_Accuracy: 0.833 Train_Accuracy: 0.945 time: 8.921875seconds\n",
      "Iter:284 Test_Accuracy: 0.828 Train_Accuracy: 0.947 time: 9.734375seconds\n",
      "Iter:285 Test_Accuracy: 0.829 Train_Accuracy: 0.948 time: 9.75seconds\n",
      "Iter:286 Test_Accuracy: 0.8295 Train_Accuracy: 0.957 time: 9.75seconds\n",
      "Iter:287 Test_Accuracy: 0.831 Train_Accuracy: 0.95 time: 12.984375seconds\n",
      "Iter:288 Test_Accuracy: 0.8305 Train_Accuracy: 0.943 time: 11.0625seconds\n",
      "Iter:289 Test_Accuracy: 0.831 Train_Accuracy: 0.945 time: 12.015625seconds\n",
      "Iter:290 Test_Accuracy: 0.831 Train_Accuracy: 0.958 time: 14.921875seconds\n",
      "Iter:291 Test_Accuracy: 0.831 Train_Accuracy: 0.955 time: 12.734375seconds\n",
      "Iter:292 Test_Accuracy: 0.8305 Train_Accuracy: 0.937 time: 10.03125seconds\n",
      "Iter:293 Test_Accuracy: 0.829 Train_Accuracy: 0.942 time: 12.921875seconds\n",
      "Iter:294 Test_Accuracy: 0.8285 Train_Accuracy: 0.94 time: 13.578125seconds\n",
      "Iter:295 Test_Accuracy: 0.831 Train_Accuracy: 0.953 time: 14.671875seconds\n",
      "Iter:296 Test_Accuracy: 0.8305 Train_Accuracy: 0.95 time: 14.140625seconds\n",
      "Iter:297 Test_Accuracy: 0.83 Train_Accuracy: 0.951 time: 14.828125seconds\n",
      "Iter:298 Test_Accuracy: 0.829 Train_Accuracy: 0.955 time: 10.484375seconds\n",
      "Iter:299 Test_Accuracy: 0.829 Train_Accuracy: 0.953 time: 9.609375seconds\n",
      "Iter:300 Test_Accuracy: 0.8295 Train_Accuracy: 0.944 time: 9.609375seconds\n",
      "Total time:  3727.90625 seconds\n"
     ]
    }
   ],
   "source": [
    "images, labels = x_train[:1000].reshape(1000, 28*28)/255 , y_train[:1000] # загружаем 1000 изображений и меток (train)\n",
    "one_hot_labels = np.zeros((1000, 10)) # готовим нулевую матрицу. По строкам обучающие примеры, по столбцам метка\n",
    "for n,l in enumerate(labels):\n",
    "    one_hot_labels[n,l] = 1 # для каждой строки в одном из столбцов ставим 1, соответствующую метке (train)\n",
    "labels = one_hot_labels # переопределяем labels (1000, 10)\n",
    "\n",
    "test_images, test_labels = x_test.reshape(-1, 28*28)/255, y_test # загружаем 1000 изображений и меток (test)\n",
    "one_hot_labels_test = np.zeros((x_test.shape[0], 10)) # готовим нулевую матрицу. По строкам обучающие примеры, по столбцам метка\n",
    "for n, l in enumerate(test_labels): # для каждой строки в одном из столбцов ставим 1, соответствующую метке (test)\n",
    "    one_hot_labels_test[n,l] = 1\n",
    "test_labels = one_hot_labels_test\n",
    "\n",
    "tanh = lambda x: np.tanh(x)\n",
    "tanh2deriv = lambda output: 1 - (output ** 2)\n",
    "softmax = lambda x: np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "\n",
    "# устанавливаем параметры\n",
    "alpha, iterations, pixels_per_image, num_labels = (2, 301, 784, 10)\n",
    "batch_size = 100\n",
    "\n",
    "input_rows, input_cols = (28, 28)\n",
    "kernel_rows, kernel_cols = (3, 3)\n",
    "num_kernels = 16\n",
    "\n",
    "# в скрытом слое будут приниматься результаты 26*26 раз просмотров каждого изображения 16-ю ядрами\n",
    "# то есть по каждому изображению в общей сложности будет 10816 прогнозов \n",
    "hidden_size = ((input_rows - kernel_rows+1) * (input_cols - kernel_cols+1)) * num_kernels # (28-3+1)*(28-3+1)*16 = 10816\n",
    "kernels = 0.02 * np.random.random((kernel_rows*kernel_cols, num_kernels)) - 0.01 # 16 ядер со случайными 9-ю весами (9,16)\n",
    "# причем веса в диапазоне от -0,01 до 0,01\n",
    "\n",
    "# инициализируем случайные веса: для каждого из 10816 прогнозов с нейронов скрытого слоя готовим по 10 весов \n",
    "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels)) - 0.1 # получаем (10816, 10) \n",
    "# причем диапазон весов от -0,1 до 0,1\n",
    "\n",
    "def get_image_section(layer, row_from, row_to, col_from, col_to):\n",
    "    '''Функция выбирает подобласть в изображении'''\n",
    "    sub_section = layer[:, row_from:row_to, col_from:col_to]\n",
    "    return sub_section.reshape(-1, 1, row_to - row_from, col_to - col_from)\n",
    "\n",
    "glob_start_time = time.process_time()\n",
    "for j in range(iterations): # итерируемся по количеству итераций\n",
    "    start_time = time.process_time()\n",
    "    correct_cnt = 0 # количество TP-прогнозов\n",
    "    for i in range(round(images.shape[0]/batch_size)): # бежим по батчам из обучающих примеров\n",
    "        batch_start, batch_end = ((i * batch_size),((i+1) * batch_size)) # 0-99, 100-199 ...\n",
    "        layer_0 = images[batch_start:batch_end,:].reshape(-1,28, 28) # подаем на входной слой изображение (100,28,28) \n",
    "        # или (128,28,28) в зависимости от размера батча\n",
    "        \n",
    "        sects = [] # пустой список для отсмотренных плиточек 3*3\n",
    "        for row_start in range(layer_0.shape[1] - kernel_rows + 1): # бежим по строкам от 0 до 28-3=25 включительно\n",
    "                                                            # и смотрим интересующую область сразу по всем изображениям в батче \n",
    "            for col_start in range(layer_0.shape[2] - kernel_cols + 1): # бежим по столбцам от 0 до 28-3 включительно\n",
    "                sect = get_image_section(layer_0, # вырезаем из одного и того же места всех изображений в батче квадрат\n",
    "                                        row_start, # будет перебираться от 0 до 25 включительно\n",
    "                                        row_start + kernel_rows, # будет перебираться от 3 до 28 включительно\n",
    "                                        col_start, # будет перебираться от 0 до 25 включительно\n",
    "                                        col_start + kernel_cols) # будет перебираться от 3 до 28 включительно\n",
    "                                        #         print(f'row_start = {row_start} col_start = {col_start}')\n",
    "                sects.append(sect) # всего д.б. 26*26 = 676 массивов-стопочек размера (128, 1, 3, 3)\n",
    "        expanded_input = np.concatenate(sects, axis=1) # соединяем массивы горизонтально (присоединяем справа) \n",
    "        # получаем (128, 676, 3, 3) - \"стену\" высотой 128, толщиной 3 и протяженностью 676\n",
    "        es = expanded_input.shape # (128, 676, 3, 3) просто форма\n",
    "        flattened_input = expanded_input.reshape(es[0]*es[1], -1) # каждый \"плитку\" 3*3 вытягиваем в строку, \n",
    "        # выкладываем в штабелем и получаем (86528, 9)\n",
    "        kernel_output = flattened_input.dot(kernels)  # получаем по 16 прогнозов для каждой \"плитки\"\n",
    "                                                        # (86528, 9).dot(9,16) = (86528,16)\n",
    "        layer_1 = tanh(kernel_output.reshape(es[0], -1)) # подаем полученные прогнозы на скрытый слой и сразу для\n",
    "                                        # последующих умножений меняем форму на (128,10816) и применяем функцию активации,\n",
    "                                        # которая загоняет полученные входные значения в диапазон от -1 до 1\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape) # создаем маску вида array([[0, 1, 0, ... 0, 0, 1]]),\n",
    "                                                                # где вероятность единиц и нулей по 50% (128,10816)\n",
    "        layer_1 *= dropout_mask * 2 # применяем маску, но умноженную на 2 \n",
    "                        # (т.к. сигнал от слоя 1 примерно в 2 раза уменьшается после применения маски, поэтому его нужно усилить)\n",
    "                        # (128,10816)\n",
    "        layer_2 = softmax(layer_1.dot(weights_1_2).reshape(-1,num_labels)) # скалярное перемножение layer_1 (128,10816) \n",
    "                                            # на веса (10816,10), получаем выходной слой (128,10) с вероятностями каждого лейбла для\n",
    "                                            # каждого изображения из батча.\n",
    "        # теперь посчитаем отклонение\n",
    "        for k in range(batch_size): # итерируемся по примерам в батче, берем каждое изображение по очереди\n",
    "            labelset = labels[batch_start:batch_end,:] # правильные ответы\n",
    "            _inc = int(np.argmax(layer_2[k,:]) == np.argmax(labelset[k,:])) # считаем количество True-Positive ответов\n",
    "            correct_cnt += _inc # учитываем True-Positive ответ (если есть)\n",
    "                                                    # в общем показателей correct_cnt для j-той итерации (по j-тому батчу)\n",
    "        layer_2_delta = (layer_2 - labels[batch_start:batch_end,:])/\\\n",
    "                                            (batch_size * layer_2.shape[0]) # считаем отклонение по выходному слою (128,10)\n",
    "                                            # делим его на на все количество примеров в батче и количество выходных нейронов layer_2\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1) # считаем отклонение по среднему слою:\n",
    "                                                        # скалярно перемножаем отклонение по выходному слою (128,10)\n",
    "                                                        # на транспонированную матрицу весов weights_1_2 (10,10816)\n",
    "                                                        # получаем вектор (128,10816) и не забываем передать градиент\n",
    "        layer_1_delta *= dropout_mask # при обратном распространении корректировать обнуленные маской нейроны не следует\n",
    "                                        # поэтому той же маской обнуляем полученные дельты\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta) # корректируем веса для выходного слоя: \n",
    "                                                            # из матрицы текущих весов (10816,10) вычитаем\n",
    "                                                            # помноженный на скорость обучения слой 1 транспонированный (10816,128)\n",
    "                                                            # скалярно помноженный на отклонение по слою 2 (128,10)\n",
    "                                                            # получаем (10816,10) - такой же формы, как и были наши веса weights_1_2\n",
    "        # корректируем веса в ядрах\n",
    "        l1d_reshape = layer_1_delta.reshape(kernel_output.shape) # меняем форму layer_1_delta на форму входного слоя (86528,16) \n",
    "        k_update = flattened_input.T.dot(l1d_reshape) # считаем дельту\n",
    "        kernels -= alpha * k_update # и вычитаем дельту, получаем обновленные веса\n",
    "        \n",
    "    test_correct_cnt = 0 # correct_cnt - количество True-Positive ответов\n",
    "\n",
    "    for i in range(test_images.shape[0]): # бежим по тестовым примерам, тут уже без батчей и корректировки весов разумеется\n",
    "        layer_0 = test_images[i,:].reshape(1,28,28) # подаем на входной слой изображение (1,28,28)\n",
    "        sects = []\n",
    "        for row_start in range(layer_0.shape[1] - kernel_rows + 1): # бежим по строкам от 0 до 28-3 включительно\n",
    "            for col_start in range(layer_0.shape[2] - kernel_cols + 1): # бежим по столбцам от 0 до 28-3 включительно\n",
    "                sect = get_image_section(layer_0,\n",
    "                                row_start, # будет перебираться от 0 до 25 включительно\n",
    "                                row_start + kernel_rows, # будет перебираться от 3 до 28 включительно\n",
    "                                col_start, # будет перебираться от 0 до 25 включительно\n",
    "                                col_start + kernel_cols) # будет перебираться от 3 до 28 включительно\n",
    "                                #         print(f'row_start = {row_start} col_start = {col_start}')\n",
    "                sects.append(sect) # всего д.б. 26*26 = 676 массивов размера (128, 1, 3, 3)\n",
    "\n",
    "        expanded_input = np.concatenate(sects, axis=1) # соединяем массивы горизонтально (присоединяем справа) получаем (128, 676, 3, 3)\n",
    "        es = expanded_input.shape # (128, 676, 3, 3)\n",
    "        flattened_input = expanded_input.reshape(es[0]*es[1], -1)\n",
    "        kernel_output = flattened_input.dot(kernels)\n",
    "        layer_1 = tanh(kernel_output.reshape(es[0], -1)) # \n",
    "        layer_2 = layer_1.dot(weights_1_2).reshape(-1,num_labels) # \n",
    "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i,:])) # учитываем True-Positive ответ (если есть)\n",
    "                                                                            # в общем показателей correct_cnt для j-той итерации\n",
    "    if j % 1 == 0:\n",
    "        print(\"Iter:\" + str(j) +\\\n",
    "             \" Test_Accuracy: \" + str(test_correct_cnt/float(test_images.shape[0])) +\\\n",
    "              \" Train_Accuracy: \" + str(correct_cnt/float(images.shape[0])) + \\\n",
    "              \" time: \" + str(time.process_time() - start_time) + \" sec\")\n",
    "print(\"Total time: \", time.process_time() - glob_start_time, \" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
